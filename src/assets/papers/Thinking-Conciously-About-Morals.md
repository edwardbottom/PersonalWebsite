---
layout: post
title:  "Thinking Consciously About Morals"
excerpt: "A Critical Analysis and Defense of Greene’s Dual Process Theory from Both a Neuroscientific and Philosophical Perspective   "
categories: jekyll update
---

In this paper, I will argue in favor of Greene’s Dual Process Theory as I believe it to be the most accurate existing model of human moral judgment. I will begin by defining the two types of thought, manual cognition and automatic cognition. I will then look at these two types of thinking in application and generalize them to deontological and consequentialist moral decisions through the Central Tension Principle. I will then critique the principle and its existing evidence. I will then criticize Greene’s theory for its ignorance of the is/ought gap with regards to connecting neuroscience to morals and its dismissal of deontological judgment in unfamiliar moral cases. I will, however, accept Greene’s claim that an “is” can constrain the implications of an “ought”, and cause us to ask new moral questions. I will then explore the implications of Greene’s favoring of consequentialism in unfamiliar cases and the limits of the automatic system. I will conclude with accepting Greene’s Dual Process Theory of morality and his Central Tension Principle.

Automatic cognition is based on instinct: the immediate response or gut reaction to a situation. Greene characterizes this thinking as “efficient” and based on the “reflexes and intuitions that guide our behavior” (Greene, 2014, p. 3). These types of quick thoughts drive much of our everyday unconscious thinking and emotional states and derive from prior experiences. They are helpful in the familiar situations that our ancestors faced and lead to the types of judgements we make every day with little thought at all. These types of judgments are not necessarily the best ideas that comes to mind in every situation, but the first.

Manual cognition is based on conscious rational thinking and intended to “serve long(er)-term goals” that are not immediately obvious in a situation (Greene, 2014, p. 3). Greene characterizes these thoughts as “typically conscious”, “experienced as voluntary”, and “often effortful” and appear when tasked with unfamiliar or difficult situations that require significant cognitive effort (Greene, 2014, p. 4). 

To better understand how these two judgments function and compete, consider debating with oneself about whether to eat a large slice of cake. Our brain’s automatic system immediately tells us that sugary foods are tasty and aid in survival, while our brain’ manual system is thinking that eating the cake is only going to make losing the next ten pounds harder. The automatic and the manual compete in situations, with the automatic favoring simple decisions often based on immediate gratification, and the manual favoring the long term and reasoned about delayed gratification. One is not necessarily better than the other, but the two work together with automatic cognition being used for quick decisions and manual cognition being used for more complex situations.

Greene argues that the two thought processes work separately, and our brains will often alternate between the two systems depending upon the situation. If a stressor is added that occupies our attention, then our brains are more apt to use the automatic setting as it is easier and more efficient and can conserve energy for other more pressing tasks. In the absence of a cognitive stressor, humans are more likely to use their slower, but more flexible and rational manual system. This process is evident in people who stress eat, as given cognitive stress, their brain takes its attention way from long term eating goals and focuses their limited manual judgments more on the cause of the stressor. Meanwhile their more readily available automatic system, which evolved to encourage eating in excess, tells them to keep eating.  

Greene cites brain scan studies to argue that these two types of thinking are distinct and occupy separate parts of the brain. Greene ties automatic thinking to the ventromedial prefrontal cortex, an area that connects directly to the amygdala, “an ancient mammalian brain structure” often tied to emotion and quick responses(Greene, 2014, p. 5). He claims the dorsolateral prefrontal cortex is responsible for manual thought processes and is located at the front of the brain, the area typically associated with higher level thought processes (Greene, 2014, p. 5). 

Greene argues that the manual and automatic systems of the brain are the inner workings of moral judgement, calling their application to moral judgement the Central Tension Principle. This theory states that “characteristically deontological judgements are supported by automatic emotional responses” and “characteristically consequential moral judgements are supported by conscious reasoning” (Greene, 2014, p. 7). Greene argues that deontological dilemmas that deal with rights, obligations, and norms are tied to emotion and the automatic and that consequentialist judgements are tied to reasoning and logical conclusions about outcomes (Greene, 2014, p. 8). Each line of thinking holds its own place in moral reasoning and explains differences in people’s responses to moral dilemmas. 

To better understand this moral distinction, consider the Trolley Problem thought experiment. The experiment entails a trolley moving towards five people on a track who will most certainly be killed. However, there is a switch which can divert the trolley to another track and instead kill one person. The question is, should you throw the switch?  A characteristically deontologist would follow their emotional response and not throw the switch as that would put a murder on their conscious, while a characteristically consequentialist would favor reason and throw the switch to save five people’s lives. In the case of the switch, people tend to act more consequentiality, but in the case of more directly affecting the one person, thus a larger cognitive stress, say pushing a large man off a bridge to stop the trolley, people tend to act more deontologically, refusing to push the large man to save five people. 

Greene gave these two Trolley Problems to people in MRI machines and found that in the deontological bridge case, the amygdala and the ventromedial prefrontal cortex were active whereas in the consequentialist switch case the dorsolateral prefrontal cortex was active (Greene, 2014, p. 11). This suggests that the two parts of the brain work independently for two different types of moral judgement and when given a more stressful and emotionally charged situation, the brain will switch from a consequentialist thought process to a deontological thought process. 

Greene cites 20 scenarios of cognitive alterations affecting either the emotional or the consequentialist perspective and finds in every case that when the ventromedial prefrontal cortex is stimulated, or the dorsolateral prefrontal cortex is restricted, responses become more deontological and vice versa for consequentialism (Greene, 2014, p. 11). The overwhelming evidence Greene provides seems to largely imply the Dual Process Theory is characteristic of the mind’s moral decisions. 

Kahane et al. believes that cases of “counter intuitive deontological judgements”, deontological decisions that are not immediately obvious and thus require higher level thought, are counter examples to the Dual Process Theory (Greene, 2014, p. 20). In the case of white lies, the deontological response is not the gut reaction 
that often characterizes deontological thinking. Rather, the consequentialist action is the more readily available case as it is much easier to lie to someone to avoid hurting their feelings, but the possibility of following one’s emotions and telling the truth would be the more cognitively controlled, but deontological thought.

Kahane et al. gave subjects counter intuitive deontological problems and found that in these cases, there was evidence on controlled cognition in fMRI scans (Greene, 2014, p. 20).  The existence of controlled deontological thinking disproves the Central Tension Principle and thus invalidates Dual Process Theory by linking the supposed two distinct types of thinking and moral reasoning to the same processes in the brain.

Greene counters Kahane et al. arguing that Kahane et al’ s fMRI scans “found no effect of counter-intuitive deontological judgments in the dorsolateral prefrontal cortex”, the part of the brain that the central tension theory links to controlled cognition and consequentialist judgements (Greene, 2014, p. 20). He argues that the lack of activity in the dorsolateral prefrontal cortex is in line with the Central Tension Principle as it keeps the two moral responses distinct in the brain. Greene’s follow up study which entailed giving participants a hard math problem, causing them to distrust their intuitions found that the uncertain participants gave more consequentialist responses to Kahane et al’s white lie dilemma as well as Trolley Problems (Greene, 2014, p. 21). Such findings are in line with the Dual Process Theory as they show the use of consequentialist thinking persisting through two separate cases of controlled cognition and not accounted for by Kahane et. al who predicted the use of controlled cognition does not define or encourage consequentialist thinking. 

However, Greene’s use of neuroscience to prove a point about morality seems to directly conflict with the is/ought gap. The is/ought gap states that just because something ought to be a certain way does not mean it is and because something is a certain way does not mean it ought to be. For example, juries ought to make good decisions, but the scientific fact is that juries can be racially biased and do not always make morally sound judgements (Greene, 2014, p. 26). That does not change the fact that juries ought to make good decisions. Greene’s use of empirical neuroscience to speculate about the inner working of moral judgements is based on the descriptive “ought” resembling the prescriptive “is”, but as shown by the jury case, the prescriptive and descriptive do not have to resemble each other.  In relation to Greene, just because the brain’s structure is inline with the dual process model, does not mean he can derive moral “oughts” from it. The world’s descriptions do not match the way the world should be. 

Although the claim that an “is” does not create an “ought” and vice versa is true, an “is” can cause us to reexamine the strength of our “oughts” and ask new questions about the “oughts”.  In the case of the jury, if juries ought to make good decisions, but juries are racially biased, we can use the new evidence and the preexisting “ought” to draw a new moral conclusion. Instead of asking if juries ought to be unbiased, we should accept the “is” that they are not unbiased, and instead assert that juries sometimes make bad decisions (Greene, 2014, p. 26). In this case, the “is” impacts the “ought” such that it causes us to assess the strength of the moral questions we ask, the “oughts”. The scientific “is” does not create a new “ought”, but it makes us change our perspective and ask newer, more significant “oughts”.  In changing our moral questions, it becomes clear that the prescriptive “is” can impact the strength of the problems we define as descriptive morals. 

Rather than speculate about moral oughts that cannot be observed or quantified in any way, Greene believes that in identifying the inner system in which we speculate about morals reveals how moral judgements can work and makes us reexamine our moral conclusions. Neuroscience allows us to observe cases in which the automatic and the manual are used to make moral decisions. In doing so, neuroscience acts as the prescriptive “is” that constrains and can strengthen or weaken our moral “oughts” by causing us to ask new, less significant but still impactful “oughts”. 

With the soundness of Dual Process Theory defined and validated both from the scientific perspective and the philosophical perspective, we can now examine the implications of the theory. Greene claims his Dual Process Theory favors a consequentialist view in that it ties deontological thinking to emotions, something highly 
variable and relative to the environment and consequentialist views to more stable higher-level thinking and reason.  Kantian thinkers have historically believed that the automatic is the product of moral reasoning and thus favorable to consequentialist thinking. If Greene is correct, one cannot reason about the deontological
as it is tied to a part of the brain linked to emotion rather than reason. Greene calls the inability of the automatic to reason the No Cognitive Miracle Principle as it would be a cognitive miracle if instinct and emotion could be applied to reason. He uses the No Cognitive Miracles Principle to argue in favor of using consequentialist reasoning over deontological reasoning when faced with unfamiliar moral problems (Greene, 2014, p. 31).

The No Cognitive Miracles principle disregards traditional Kantian philosophy in that it equates deontological thinking to acts of relative impulse, not innate moral judgements. He cites the inconsistency of the automatic systems and its tendency to favor rights and duties over good consequences and favorable outcomes (Greene, 2014, p. 35). In the switch case of the trolley problem, the deontologist favors not using the one individual as a means to save five other people but does not consider the morality of striving for the ideal long-term  situation. In cases like the Trolley Problem that are not familiar and thus lack predefined morals, Greene believes we should favor reason and the manual system to try to maximize the best outcome rather than trying to define and debate between arbitrary rights and dignities. 

I believe Greene’s decision to stray away from Kantian deontology was a wise one. Deontology tends to run into  problems in which a small violation could lead to massive consequences. In the famous case of lying to a murder to save someone’s life, Kant bites the bullet and says that it is morally wrong to lie in all situations as it uses someone else as a means, and the murder is the moral violation of the murderer not the liar (Greene, 2014, p. 19). However, what seems like common sense would tell us that it would be worse to let someone die than to lie to someone.

Along the same lines, using purely cognitive processing can be morally problematic as well and emotions are often necessary to make morally sound decisions. Such a view could be seen as immoral in that it disregards emotions in favor of reason alone and would fail in cases such as using too many resources on a single patient.Pulling the plug would allow for the use of life saving resources on other patients but ending someone’s life when it could be continued could be a moral violation to an individual and be seen as morally wrong by many. Likewise, many would question the morality of pushing someone off a footbridge to save a few lives and would probably call the person who did it a murderer and not a hero. 

Greene’s decision to propose characteristically deontological and consequentialist judgements allows him to avoid the pitfalls of purely cognitive or emotional judgement. Dealing in absolutes tends to be problematic and would make his Dual Process Theory seem unnecessary. If one system is to be ignored almost entirely, there is hardly a need to acknowledge the system or its benefits. Greene states we should “distrust our automatic settings and rely more heavily on manual mode” in cases of “practical moral disagreements that do not appear to be based on moral facts” (Greene, 2014, p. 34). Greene does not believe that the automatic system is wrong, but more so incapable of dealing with issues that are not familiar to our existing moral systems.

Greene’s distinction between the use of the automatic and the manual is based the familiarity of the situation. Greene defines unfamiliar by equating recent developments and topics of disagreement to the unfamiliar, arguing that new or uncertain decisions should not be left to intuition alone and should be reasoned about (Greene, 2014, p. 31). This view makes sense, as it is difficult to instinctively have an answer to moral dilemmas about something new and controversial like climate change or stem cell research as they are recent and complex developments. They cannot be solved through emotion alone and they have no preexisting morals. Thus, according to Greene the automatic system is unfit to deal with them, and they should be left to the manual system and  reason to maximize the most wholistic and logical outcome.

Greene then claims that most moral dilemmas we face today are unfamiliar as our current environment does not match our evolved environment. Likewise, if an issue is to bring about a moral dilemma, it is probably something that is debatable and does not have predefined moral rules. Greene’s No Cognitive Miracles Principle argues that we should not use the automatic system in unfamiliar cases, as it would take a cognitive miracle for the automatic system to reason about something unfamiliar (Greene, 2014, p. 31). The automatic system is a system that evolves from genetics, culture, and trial and error and thus will respond well to problems it evolved to solve like not starving to death or determining the morality of killing someone in cold blood (Greene, 2014, p. 31). It is unfit in unfamiliar situations that require manual cognitive thought like driving a car or trolley problems. 

Greene’s view could be criticized as there may be unfamiliar cases that favor the automatic system and emotion. I would provide a counterexample to Greene but doing so would be rather difficult. In the face of any counter that claims the emotional response is correct, Greene could argue that unfamiliar cases can resemble familiar cases; the automatic system derives in part but not entirely from trial and error of the manual system. Familiar cases were at one point unfamiliar and should have but did not necessarily use reason to solve them. In such cases, its not hard to see how reason, and not emotion ultimately derived the correct response as the unfamiliar can resemble the familiar and emotion can be derived from reason but does not have to be. It is still ideal that we use reason as it is more consistent than emotion and favors an ideal outcome from a purely logical standpoint. 

In conclusion, I believe that Greene’s use of neuroscience to observe and reason about moral judgement through cognition has valid empirical evidence and is such that its “is” constrains the significance of the “ought” enough to apply the Dual Process Theory of cognition to morality through the Central Tension Principle. He provides an overwhelming amount of support for his Dual Process Theory in the form of neuroscientific studies and effectively defends the studies and then generalizes the studies to moral judgement. I believe his decision to favor controlled thinking and consequentialism in unfamiliar (most) cases is justified as when morals are ambiguous, it is best to favor the best possible logical outcome as opposed to trying to define ambiguous morals and rights. 

References
Greene, J. (2014). Beyond Point-and-Shoot Morality: Why Cognitive (Neuro)Science Matters for Ethics. Ethics, 124(4), 695-726. doi:10.1086/675875