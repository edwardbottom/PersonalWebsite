---
layout: post
title:  "A Rebuttal for the System's reply to Searle's Chinese Room Arguement"
excerpt: "Why Turing Machines are valid models of the mind"
categories: jekyll update
---

Searle argues that computers, no matter how advanced technology gets, will never be able to accurately model the mind. He believes this because computers or Turing machines are purely syntax machines, operating by manipulating symbols, and have no way of understanding or giving semantic meaning to symbols which is the defining feature of the human mind. 


Searle specifically references a room run by a man that can take in Chinese characters and return valid responses to any Chinese input. Searle claims that such a room is a valid Turing machine, which it is, and that the man does not understand Chinese, so the system is not intelligent. I find Searle’s claim here to be one sided and side with the systems response to the Chinese room argument. Specifically, that the entire system is intelligent, and the man or central processor’s intelligence is irrelevant to the intelligence of the system. 


Rather, focusing too heavily on the man or the central processing unit is as absurd as focusing on only one portion of the brain. The amygdala is not capable of understanding and neither is a single neuron in the brain. People, like Turing machines, are systems and our existence and functionality are not tied exclusively to one part of our mind; it is a system and the processor is not localized to one region. Searle places to much focus on the man inside the machine’s understanding and intentionality, when that is irrelevant to the understanding of Chinese. The entire system can fluently communicate with Chinese speakers, and if it is able to use language at the level of native speakers and ascribe syntax to symbols and meanings then it has semantic understanding by virtue of its use of language. 


If the system were asked to explain the meaning or thought of something, the current system would have no trouble giving a meaning and definition to a symbol it output. The man in the system does not need to have semantic understanding of the words, because he is merely a place holder for a piece of the system. The system itself has a semantic understanding if it can functionally respond to the inputs it is given; this is the essence of machine functionalism. Obviously, humans do not have a tape running through their mind or a small person giving them inputs and outputs. The argument Searle presents ignores the definition of functionalism, that mental properties are defined purely by what they do and not what they are. In the case of the Chinese room argument, the room is more than capable of intelligent communication and thus has semantic understanding and if the room has semantic understanding the modus tollens Searle uses to make his proof is no longer valid. 