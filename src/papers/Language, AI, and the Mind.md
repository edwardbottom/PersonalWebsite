---
layout: post
title:  "Communicating, Calculating and Charting the Mind: Using Language Processing to Model the Mind as a Computer"
excerpt: "A paper discussing computers' ability to model language and its relation to their ability to model human thought. "
date:   2015-11-17 16:16:01 -0600
categories: jekyll update
---


Language is the defining feature of the human mind, “our most sophisticated cognitive feature” (Bermudez 30). It exists innately in all humans and in no other species. Language is the biproduct of the mind continuously running algorithms to interpret the hierarchal structure of incoming data. This process is no different than what computers do in that they take in information, perform a series of purely mechanical steps, and then output a result. Alan Turing’s Church Turing Thesis states that “anything done by an algorithm can be done by a Turing Machine (computer)” (13). Terry Winograd’s SHRDLU and other language processing artificial intelligences demonstrate similarities between computers and human processing in that they use a purely mechanical process to take in inputs, manipulate data, and output results in a systematic and purely mathematical manner, thus creating a possible computer based model of how the mind processes language. 


Language is hierarchal, and a complex behavior done by almost every human. By analyzing the deep structure of language, one can see “how it is built up from basic constituents according to basic rules” (17). These basic semantic rules can be thought of as algorithms. To illustrate this idea, consider the sentence “Joe has worn those shoes”. Such a sentence seems trivial at first and could be thought of with little to no thought, subconsciously. However, upon analyzing the deep structure of the language, things become more complex. The sentence itself is made up of a noun denoting the subject, an auxiliary verb marking tense, a verb to create action, a descriptive determiner, and a noun acting as the direct object. Each of these sections can then be combined into a noun phrase, Joe, and a verb phrase, has worn those shoes. The verb and the noun phrase can then combine into a sentence. This example illustrates how simple ideas and categorizations of words form the hierarchical structure of language, becoming more complicated at each increasing level and how one can break down the hierarchal structure algorithmically. 


Analyzing language syntax brings together the ideas that “language involves stored bodies of information” and “that these bodies of information can be manipulated algorithmically (19). The first of these ideas is evident in that language exists to communicate an idea between two people: a sort of transfer of information from mind to mind. Thus, as in the case with computers, information must be taken in and some information must already be present for the algorithmic process to work. The manipulation of strings of information into sentences is algorithmic in that certain patterns exist every time we create a sentence. For example, every complete sentence in English has a noun phrase and a verb phrase, but most people do not consciously think of this when speaking. Rather, they have done the same algorithms so many times that it happens automatically and a sentence without a noun phrase: “ran to the store” just seems incomplete for no reason to a lot of people. They do not immediately realize a noun phrase is missing or that noun phrases exist at all. Chomsky argued the processes that underlie language exist innately in humans and no other creatures and that language processing occurs subconsciously. 


Attempts at AI have tried to further model the idea of language as an algorithmic process by developing computers that process langauge. Such an example would provide an adequate model for the mind since effective communication through language “underpins our political and social structures” and defines humans so much so that Bermudez refers to humans as “homo linguisticus” rather than homo sapiens (30). 


One of the early attempts at AI was Terry Winograd’s SHRDLU, which was capable of “using language to report on its environment, to plan actions, and to reason about the implications of what is being said to it” (31). SHRDLU used text commands to respond to and interact with a microworld of shapes. To do this, SHRDLU implemented algorithms like the ones described earlier for syntactic structure to not only read in information, but also output information using syntactic structure.  


SHRDLU’s three major features are that it performs syntactic analysis, semantic analysis, and that it integrates preexisting information with new information acquired by the user (34). This integration is interesting to cognitive scientists and linguists because it integrates Chomsky’s hierarchal model of linguistics with realistic and reliable algorithms for understanding how humans process memory with existing information. The syntactic analysis serves as the input to the computer and the mind, allowing for incoming strings of data to be analyzed and the nouns, verbs, subjects, and objects to be pulled from the data to determine the meaning. This process mimics that of what humans do in that it searches the sentence for meaning based on predictable structure and reoccurring patterns: the essence of Chomsky’s deep structure. SHRDLU’s design allows for the creation of a new idea using the preexisting knowledge gathered from linguistic analysis as well as a data base that stores the knowledge already known about the microworld. 


To better illustrate SHRDLU’s analysis, consider the cognitive-deductive algorithm for SHRDLU described below to determine if a string of characters is a sentence using the syntactic analysis described earlier (18). The algorithm parses the string and looks for a noun phrase, if one exists, it looks for a verb phrase. If a noun or a verb phrase cannot be found, the string is not a sentence. Then the string is scanned for any remaining words that are not part of a verb phrase or a noun phrase. If any exist, the string is not a sentence. This example illustrates how SHRDLU uses the reoccurring patterns of deep structure to process information in a systematic and mathematical manner. It looks for key features of all sentences and uses them to determine the meaning and validity of communication. 


SHRDLU represents a purely mechanical way to model humanity’s most defining feature, language through many interacting and independent cognitive processes. Such a model is applicable to the brain in that the many regions and neurons of the brain are highly specialized and systematic, often overlapping in their procedures and functions when performing a task (62). SHRDLU models this process remarkably well for a primitive implementation of language and AI and laid the foundation for the mind existing as a computer model through the implementation of algorithms. 


However, SHRDLU does have shortcomings in its ability to model language. SHRDLU’s “conversations” exist as unrelated questions and answers and lack depth and the ability to come up with natural flowing conversation and original ideas. Rather, its sentences are robotic, limited in structure, and only deal with the microworld itself. SHRDLU is unable to make assumptions and connect ideas about objects and events, often asking for clarification of “which pyramid” or “where exactly” (37).  Likewise, its language is short and primitive at best with simple responses such as “the pyramid”, “the blue pyramid and the blue box”, and “I don’t understand which pyramid you mean” (37). SHRDLU’s algorithms limit it to simple responses and do not have the ability to infer ideas, making it seem inadequate. Perhaps there is an innateness or complexity in humans that cannot be grasped by any other species or even a computer model.


To contrast this, one could also see SHRDLU’s limitations as more of an inadequacy of technology and that the ideas currently present in SHRDLU could be evolved and further implemented to create a more intelligent language processor. One could see SHRDLU’s limited capacity to the microworld as a limited form of language processing. Humans are extremely well adapted at learning language and taking in information from their environment; they have had hundreds of thousands of years to evolve their ability while SHRDLU was made in only a few years. Thus, it should be expected that its knowledge and structure should be limited and rather than focusing on its limitations, one should focus more on its potential and applications to furthering algorithmic language processing. 
Rather if SHRDLU’s data base were to be refined to encompass more information about the microworld or perhaps the world itself, SHRDLU may then be able to engage in more complex conversation. SHRDLU’s shortcomings do not invalidate the algorithms it uses, rather its successes confirm their viability. One cannot deny that SHRDLU effectively communicates ideas about its environment and answers questions in a somewhat intelligent manner. The human mind is far more complex that the algorithms implemented in SHRDLU. The algorithms need to be developed further and implemented on a more complex scale. SHRDLU was not made to be perfect, Winograd willingly admits that (38), and it should not be treated as perfect and rather seen as a limited, but successful form of language processing. 
SHRDLU’s success is its implementation of algorithms on the hierarchal structure of language. It implements what Chomsky theorized: that analysis of deep structure could mimic the processing of language by the brain. More importantly, that it could be done in a purely mechanical sense, making it applicable to the Church-Turing Thesis “that anything that can be done by an algorithm can be done by a Turing machine” (13) or computer. 


Humans are often viewed as a species above all other species due to their intellectual achievements and intricate language. However, the successful implementation of language algorithms suggests language can exist without “ambiguity or intuition” (15) as in the case of SHRDLU’s language processing algorithms. Language, although complicated and seemingly unique to humans, can be modeled by a computer that systematically builds up the increasing complexity of language from simple rules about deep structure to complete well-formed formulas. The neural networks in the human mind may implement mechanical algorithms for language processing similar to those outlined by Chomsky and implemented in SHRDLU. Thus if language, the defining feature of the human mind, can be done purely mechanically, the Church-Turing Thesis would suggest the mind functions like and can be modeled by a computer. 

Work Cited


BermuÌdez, JoseÌ Luis. Cognitive Science: An Introduction to the Science of the Mind. Cambridge University Press, 2014.
